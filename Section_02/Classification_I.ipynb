{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Section 02: Classification I\n",
        "\n",
        "<a rel=\"license\" href=\"https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode.txt\"><img alt=\"Attribution-NonCommercial-ShareAlike 4.0 International\" src=\"https://mirrors.creativecommons.org/presskit/buttons/88x31/svg/by-nc-sa.eu.svg\" title=\"This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International Public License\"/></a>\n"
      ],
      "metadata": {
        "id": "MAPrwzqyEJMy"
      },
      "id": "MAPrwzqyEJMy"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Contents\n",
        "\n",
        "- [Introduction](#introduction)\n",
        "- [Install and Import Required Packages](#installation)\n",
        "- [Creating a Training Dataset](#training-dataset)\n",
        "    - [Simulation](#simulation)\n",
        "        - [Task 1](#task1)\n",
        "    - [Labelling Training Data](#labelling)\n",
        "        - [Task 2](#task2)\n",
        "        - [Task 3](#task3)\n",
        "    - [Calculating Input Features](#features)\n",
        "        - [Task 4](#task4)\n",
        "- [Creating a Logistic Regression Model](#modelling)\n",
        "    - [Training](#training)\n",
        "    - [Test](#test)\n",
        "        - [Prediction](#prediction)\n",
        "        - [Evaluation](#evaluation)\n",
        "    - [Task 5: Comprehensive Application](#task5)\n",
        "- [Summary](#summary)\n"
      ],
      "metadata": {
        "id": "-WjMyYZpJkBc"
      },
      "id": "-WjMyYZpJkBc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"introduction\"></a>\n",
        "## Introduction"
      ],
      "metadata": {
        "id": "DDt-mkz1ElNR"
      },
      "id": "DDt-mkz1ElNR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we begin to train our machine learning models with **supervised learning**, which is a novel paradigm for population genetic problems ([Schrider and Kern 2018](https://doi.org/10.1016/j.tig.2017.12.005)). Usually, there are two primary questions that can be addressed using supervised learning.\n",
        "1. **Classification**: Categorizing data into predefined classes, ideal for tasks where the output is a discrete label.\n",
        "2. **Regression**: Dealing with continuous quantities, suitable for tasks like forecasting numerical values.\n",
        "\n",
        "Classification and regression problems are commonly encountered in population genetics. For instance, the detection of genome segments originating from introgression can be approached as a classification problem. This is because each genome segment can be categorized as either belonging to the 'introgression' class or the 'non-introgression' class. Conversely, estimating the proportion of introgression within a genome can be treated as a regression problem since this proportion represents a continuous quantity.\n",
        "\n",
        "[Introgression](https://en.wikipedia.org/wiki/Introgression) refers to the transfer of genetic material from one lineage to another between two deeply divergent populations or species. This process is illustrated in the figure below:\n",
        "\n",
        "![introgression.png](data:image/png;base64,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)\n",
        "\n",
        "Due to [genetic recombination](https://en.wikipedia.org/wiki/Genetic_recombination) events, which can break and recombine genomic sequences, the genomes in the recipient population may contain segments derived from the donor population. These segments are referred to as introgressed fragments. In this context, the 'reference population' is defined as the population without introgressed fragments, the 'target population' is the one that receives introgressed fragments, and the 'source population' is the one donating these fragments to the target population.\n",
        "\n",
        "Here, we will utilize [logistic regression](https://en.wikipedia.org/wiki/Logistic_regression) to detect ghost introgressed fragments in genomes. The term 'ghost' refers to introgressed fragments originating from source populations with no known genome sequences. Although the term 'regression' appears in logistic regression, it is typically applied to binary classification problems that only contain two possible outcomes. This is because logistic regression involves two key components:\n",
        "1. Establishing a linear combination $Z$ of the input feature $X=(X_1, X_2, \\dots, X_n)$: $Z=\\beta_0+\\beta_1X_1+\\beta_2X_2+\\dots+\\beta_nX_n$, where $\\beta_0, \\beta_1, \\beta_2, \\dots, \\beta_n$ are parameters estimated in logistic regression.\n",
        "2. Converting $Z$ to a probability $Pr(Y=1|X)$ by the logistic function: $Pr(Y=1|X)=\\sigma(Z)=1/(1+e^{-Z})$.\n",
        "\n",
        "This model outputs a probability that $Y$ belongs to one of the two classes, for example, '0' (representing the non-introgression class) and '1' (denoting the introgression class), making it suitable for binary classification. A decision threshold, often set at 0.5, is then used to categorize this probability into binary outcomes. The term 'regression' in logistic regression is derived from its linear regression approach to modeling the [log-odds](https://en.wikipedia.org/wiki/Logit):\n",
        "\n",
        "$$\\text{logit}[Pr(Y=1|X)]=\\ln\\left[\\frac{Pr(Y=1|X)}{1-Pr(Y=1|X)}\\right]=\\beta_0+\\beta_1X_1+\\beta_2X_2+\\dots+\\beta_nX_n$$\n",
        "\n",
        "but its application is distinctly suited to classification problems.\n",
        "\n",
        "The logistic function is well-known for its characteristic S-shape, as shown below:"
      ],
      "metadata": {
        "id": "Iz4Mj3RbNdCe"
      },
      "id": "Iz4Mj3RbNdCe"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "z = np.linspace(5, -5, 100)\n",
        "plt.xlabel('$Z$')\n",
        "plt.ylabel('$Pr(Y=1|X)$')\n",
        "plt.plot(z, 1/(1+np.exp(-z)), 'r-', lw=5, alpha=0.6)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RvLfkH0l-u-_"
      },
      "id": "RvLfkH0l-u-_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"installation\"></a>\n",
        "## Install and Import Required Packages"
      ],
      "metadata": {
        "id": "rBLqf2pwWjIq"
      },
      "id": "rBLqf2pwWjIq"
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install demes demesdraw msprime pyranges scikit-allel scikit-learn tskit\n",
        "!wget -c https://raw.githubusercontent.com/xin-huang/pgml/main/Section_02/utils.py\n",
        "\n",
        "# Import required packages\n",
        "import allel, demes, demesdraw, msprime, os, pickle, scipy, tskit\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pyranges as pr\n",
        "from scipy.spatial import distance_matrix\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "PSaakRYNUbUo"
      },
      "id": "PSaakRYNUbUo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "41aeff97",
      "metadata": {
        "id": "41aeff97"
      },
      "source": [
        "<a name=\"training-dataset\"></a>\n",
        "## Creating a Training Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "caa87044",
      "metadata": {
        "id": "caa87044"
      },
      "source": [
        "<a name=\"simulation\"></a>\n",
        "### Simulation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4747ea0b",
      "metadata": {
        "id": "4747ea0b"
      },
      "source": [
        "To obtain a good machine learning model, we first need to collect enough training data. Fortunately, we can use simulation to create a training dataset in this tutorial. Here, we will use [msprime](https://tskit.dev/msprime/docs/stable/intro.html) \\([Baumdicker et al. 2022](https://doi.org/10.1093/genetics/iyab229)\\) to simulate data with a demographic model from [Durvasula and Sankararaman (2019)](https://doi.org/10.1371/journal.pgen.1008175), which is a simplified demographic model for the [Neanderthal](https://en.wikipedia.org/wiki/Neanderthal) introgression to modern humans. We have converted the demographic model into the [Demes](https://popsim-consortium.github.io/demes-docs/latest/introduction.html) format ([Gower et al. 2022](https://doi.org/10.1093/genetics/iyac131)). The demographic model is shown below:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/sriramlab/ArchIE/blob/master/simulations/ms.sh#L7C48-L7C179\n",
        "archie_3D19 = \"\"\"\n",
        "doi:\n",
        "    - https://doi.org/10.1371/journal.pgen.1008175\n",
        "time_units: generations\n",
        "demes:\n",
        "    - name: ancestral\n",
        "      epochs:\n",
        "          - {end_time: 2500, start_size: 10000}\n",
        "    - name: source\n",
        "      ancestors: [ancestral]\n",
        "      start_time: 12000\n",
        "      epochs:\n",
        "          - {end_time: 6120, start_size: 10000}\n",
        "          - {end_time: 6000, start_size: 100}\n",
        "          - {end_time: 0, start_size: 10000}\n",
        "    - name: reference\n",
        "      ancestors: [ancestral]\n",
        "      epochs:\n",
        "          - {end_time: 0, start_size: 10000}\n",
        "    - name: target\n",
        "      ancestors: [ancestral]\n",
        "      epochs:\n",
        "          - {end_time: 0, start_size: 10000}\n",
        "pulses:\n",
        "    - {sources: [source], dest: target, time: 2000, proportions: [0.02]}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "MzyfbvvYm7mG"
      },
      "id": "MzyfbvvYm7mG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can visualize this demographic model with the following codes:"
      ],
      "metadata": {
        "id": "1gItGixbo3gP"
      },
      "id": "1gItGixbo3gP"
    },
    {
      "cell_type": "code",
      "source": [
        "demesdraw.tubes(demes.loads(archie_3D19))"
      ],
      "metadata": {
        "id": "BNl4r7ZtnIXz"
      },
      "id": "BNl4r7ZtnIXz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this demographic model, the target population is the population that receives gene flow (the dash arrow) from the source population, whereas the reference population is the population does not contain genetic materials from the source population. We have implemented a function `simulate_data()` below to simulate genomes from a specified demographic model."
      ],
      "metadata": {
        "id": "i3mOmINdocA2"
      },
      "id": "i3mOmINdocA2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cecfbf1a",
      "metadata": {
        "id": "cecfbf1a"
      },
      "outputs": [],
      "source": [
        "def simulate_data(demog: str, nref: int, ntgt: int, ref_id: str, tgt_id: str,\n",
        "                  seq_len: int, mut_rate: float, rec_rate: float, ploidy: int,\n",
        "                  output_dir: str, output_prefix: str, seed: int = None) -> None:\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Simulates sequence data with a given demographic model by msprime.\n",
        "\n",
        "    Arguments:\n",
        "        demog str: String of the demographic model in the Demes format.\n",
        "        nref int: Number of individuals sampled from the reference population.\n",
        "        ntgt int: Number of individuals sampled from the target population.\n",
        "        ref_id str: Name of the reference population in the demographic model.\n",
        "        tgt_id str: Name of the target population in the demographic model.\n",
        "        seq_len int: Length of the simulated sequence.\n",
        "        mut_rate float: Mutation rate per base pair per generation.\n",
        "        rec_rate float: Recombination rate per base pair per generation.\n",
        "        ploidy int: Ploidy of the simulated genome.\n",
        "        output_dir str: Name of the output directory.\n",
        "        output_prefix str: Prefix of the output file name.\n",
        "        seed int: Random seed.\n",
        "\n",
        "    Returns:\n",
        "        None.\n",
        "    \"\"\"\n",
        "    demography = msprime.Demography.from_demes(demes.loads(demog))\n",
        "    samples = [\n",
        "        msprime.SampleSet(nref, ploidy=ploidy, population=ref_id),\n",
        "        msprime.SampleSet(ntgt, ploidy=ploidy, population=tgt_id),\n",
        "    ]\n",
        "\n",
        "    ts = msprime.sim_ancestry(\n",
        "        recombination_rate=rec_rate,\n",
        "        sequence_length=seq_len,\n",
        "        samples=samples,\n",
        "        demography=demography,\n",
        "        record_migrations=True,\n",
        "        random_seed=seed,\n",
        "    )\n",
        "    ts = msprime.sim_mutations(ts, rate=mut_rate, random_seed=seed,\n",
        "                               model=msprime.BinaryMutationModel())\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    ts_file = f'{output_dir}/{output_prefix}.ts'\n",
        "    vcf_file = f'{output_dir}/{output_prefix}.vcf'\n",
        "    ref_ind_file = f'{output_dir}/{output_prefix}.ref.ind.list'\n",
        "    tgt_ind_file = f'{output_dir}/{output_prefix}.tgt.ind.list'\n",
        "\n",
        "    ts.dump(ts_file)\n",
        "    with open(vcf_file, 'w') as o: ts.write_vcf(o)\n",
        "\n",
        "    with open(ref_ind_file, 'w') as f:\n",
        "        for i in range(nref):\n",
        "            f.write(f'tsk_{i}\\n')\n",
        "\n",
        "    with open(tgt_ind_file, 'w') as f:\n",
        "        for i in range(i+1, nref + ntgt):\n",
        "            f.write(f'tsk_{i}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"simulation-example\"></a>\n",
        "Here is an example demonstrating how to use the `simulate_data()` function. We simulate data using the above demographic model `archie_3D19`, sampling 50 diploid individuals from the reference population and another 50 diploid individuals from the target population. The mutation rate is set at 1.25e-8 per base pair per generation, and the recombination rate at 1e-8 per base pair per generation. We limit the simulation to a sequence of 50,000 base pairs (bp) in length, because we will divide a longer genome into segments of 50 kbp and determine whether a given segment represents an introgressed fragment. We also specify a seed `555` for the random number generator to ensure we can get the same result."
      ],
      "metadata": {
        "id": "XAX7_hkRuoxT"
      },
      "id": "XAX7_hkRuoxT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db1daa99",
      "metadata": {
        "id": "db1daa99"
      },
      "outputs": [],
      "source": [
        "simulate_data(demog=archie_3D19, nref=50, ntgt=50, ref_id='reference',\n",
        "              tgt_id='target', seq_len=50000, mut_rate=1.25e-8, rec_rate=1e-8,\n",
        "              ploidy=2, output_dir='examples', output_prefix='example.training',\n",
        "              seed=555)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After simulation, we can find a [tree-sequence](https://tskit.dev/tutorials/what_is.html) file `example.training.ts` and a [VCF](https://samtools.github.io/hts-specs/VCFv4.2.pdf) file `example.training.vcf` in the `example` folder using the following shell command:"
      ],
      "metadata": {
        "id": "W41FV2vuwkGd"
      },
      "id": "W41FV2vuwkGd"
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l examples"
      ],
      "metadata": {
        "id": "c6YuGQjDtaCT"
      },
      "id": "c6YuGQjDtaCT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tree-sequence is an efficient way to store genetic data ([Kelleher et al. 2019](https://doi.org/10.1038/s41588-019-0483-y)). The tree-sequence file `example.training.ts` records a lot of information from the simulation, for example, the introgressed fragments. However, since this file is in a binary format, it is not human-readable. To address this, we create an additional file, `example.training.vcf`, which contains the simulated genomes in a format that can be easily read by humans. Now we can examine the first 10 lines in `example.training.vcf` with the following shell command:"
      ],
      "metadata": {
        "id": "R4iC2qLIxmnm"
      },
      "id": "R4iC2qLIxmnm"
    },
    {
      "cell_type": "code",
      "source": [
        "!head -10 examples/example.training.vcf"
      ],
      "metadata": {
        "id": "9Euo8SzBt8z7"
      },
      "id": "9Euo8SzBt8z7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Besides, two files `example.training.ref.ind.list` and `example.training.tgt.ind.list` specify the individuals from the reference and target populations, respectively. For example, we can find the first five individuals from the reference population using the following command:"
      ],
      "metadata": {
        "id": "k4MhF8d6WD_v"
      },
      "id": "k4MhF8d6WD_v"
    },
    {
      "cell_type": "code",
      "source": [
        "!head -5 examples/example.training.ref.ind.list"
      ],
      "metadata": {
        "id": "36npfUPEWTqQ"
      },
      "id": "36npfUPEWTqQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1115cbdf",
      "metadata": {
        "id": "1115cbdf"
      },
      "source": [
        "<a name=\"task1\"></a>\n",
        "**Task 1:** Please use the `simulate_data()` function with the same parameter settings from the above example to create a training dataset with 100 replicates. However, modify `output_dir='examples'` to `output_dir='training'` and change `output_prefix='example.training'` to `output_prefix='lr.training'`. Then we can create a training dataset with suffcient amount of simulated data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a99d3a04",
      "metadata": {
        "id": "a99d3a04"
      },
      "outputs": [],
      "source": [
        "# Please implement your code here.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "  <summary>\n",
        "    <font size=\"3\" color=\"darkgreen\">\n",
        "      <b>Click for hints</b>\n",
        "    </font>\n",
        "  </summary>\n",
        "\n",
        "  1. To simulate data across 100 replicates, implement a for-loop using `for i in range(100):`. This loop should encapsulate the following command from the previous [example](#simulation-example):\n",
        "  \n",
        "    ```\n",
        "    simulate_data(demog=archie_3D19, nref=50, ntgt=50, ref_id='reference',\n",
        "                   tgt_id='target', seq_len=50000, mut_rate=1.25e-8, rec_rate=1e-8,\n",
        "                   ploidy=2, output_dir='examples', output_prefix='example.training',\n",
        "                   seed=555)\n",
        "    ```\n",
        "  2. Modify the `output_dir` parameter from `output_dir='examples'` to `output_dir='training'` to direct the output to the correct directory.\n",
        "  3. It is essential to modify the `output_prefix` parameter for each replicate to prevent overwriting. Use the [Python f-string feature](https://www.geeksforgeeks.org/formatted-string-literals-f-strings-python/) for this: `output_prefix=f'lr.training.{i}'`. The `f` before the quotation marks denotes a formatted string, allowing you to embed expressions, like `{i}`, inside the string. These expressions are evaluated at runtime, which means the value of `i` is dynamically inserted into the string, as `i` varies with each iteration. So, for each iteration, you get a unique output prefix like `lr.training.0`, `lr.training.1`, and so on, ensuring each file is distinct.\n",
        "  4. Remove the `seed` parameter. If you use the same seed for all simulations, you will end up with identical data in each replicate. This is not good for training machine learning models because these models learn better from a variety of different examples. If a model only sees the same data over and over, it will not learn effectively. By not setting a `seed`, each simulation creates different data, giving the model a wider range of examples to learn from. This helps the model to understand and predict new, unseen data more accurately in the future.\n",
        "\n",
        "  - <details>\n",
        "      <summary>\n",
        "        <font size=\"3\" color=\"darkblue\">\n",
        "          <b>Click for solutions</b>\n",
        "        </font>\n",
        "      </summary>\n",
        "\n",
        "    ```\n",
        "    for i in range(100):\n",
        "        simulate_data(demog=archie_3D19, nref=50, ntgt=50, ref_id='reference',\n",
        "                      tgt_id='target', seq_len=50000, mut_rate=1.25e-8, rec_rate=1e-8,\n",
        "                      ploidy=2, output_dir='training', output_prefix=f'lr.training.{i}')\n",
        "    ```\n",
        "  </details>\n",
        "</details>"
      ],
      "metadata": {
        "id": "kvUk0HgxS3N_"
      },
      "id": "kvUk0HgxS3N_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can examine the first ten files in the `training` folder using the following shell command:"
      ],
      "metadata": {
        "id": "S8Qxuv6q9Ctf"
      },
      "id": "S8Qxuv6q9Ctf"
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l training | head -10"
      ],
      "metadata": {
        "id": "_iTVXvk1xNql"
      },
      "id": "_iTVXvk1xNql",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "11a6ac95",
      "metadata": {
        "id": "11a6ac95"
      },
      "source": [
        "<a name=\"labelling\"></a>\n",
        "### Labelling Training Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For supervised learning, it is necessary to supply the ground truth to the machine learning model. In our tutorial, we need to inform the model about which fragments are introgressed and which are not. This necessity underlines why we use simulation to create the training dataset: it allows us to determine the ground truth regarding introgressed fragments within the simulated data. Below, we have developed the function `get_true_tracts()` to extract the true introgressed fragments from a given tree-sequence file.\n"
      ],
      "metadata": {
        "id": "cp3jnP27bOtN"
      },
      "id": "cp3jnP27bOtN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3e4f7c8",
      "metadata": {
        "id": "e3e4f7c8"
      },
      "outputs": [],
      "source": [
        "def get_true_tracts(ts_file: str, tgt_id: str, src_id: str, ploidy: int,\n",
        "                    bed_file: str) -> None:\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Obtains true introgressed tracts at the haploid level\n",
        "        from a given tree-sequence file.\n",
        "\n",
        "    Arguments:\n",
        "        ts_file str: Name of the tree-sequence file.\n",
        "        tgt_id str: Name of the target population.\n",
        "        src_id str: Name of the source population.\n",
        "        ploidy int: Ploidy of the genomes.\n",
        "        bed_file str: Name of the output file storing the true introgressed\n",
        "                      tract in the BED format.\n",
        "\n",
        "    Returns:\n",
        "        None.\n",
        "    \"\"\"\n",
        "    tracts = pd.DataFrame(columns=['Chromosome', 'Start', 'End', 'Sample'])\n",
        "\n",
        "    ts = tskit.load(ts_file)\n",
        "    src_id = [p.id for p in ts.populations() if p.metadata['name']==src_id][0]\n",
        "    tgt_id = [p.id for p in ts.populations() if p.metadata['name']==tgt_id][0]\n",
        "\n",
        "    for m in ts.migrations():\n",
        "        if (m.dest==src_id) and (m.source==tgt_id):\n",
        "            for t in ts.trees():\n",
        "                if m.left >= t.interval.right: continue\n",
        "                if m.right <= t.interval.left: break\n",
        "                for n in ts.samples(tgt_id):\n",
        "                    if t.is_descendant(n, m.node):\n",
        "                        if m.left > t.interval.left:\n",
        "                            left = m.left\n",
        "                        else:\n",
        "                            left = t.interval.left\n",
        "                        if m.right < t.interval.right:\n",
        "                            right = m.right\n",
        "                        else:\n",
        "                            right = t.interval.right\n",
        "                        tracts.loc[len(tracts.index)] = [\n",
        "                            1, int(left), int(right),\n",
        "                            f'tsk_{ts.node(n).individual}_{int(n%ploidy+1)}'\n",
        "                        ]\n",
        "\n",
        "    open(bed_file, 'w').close()\n",
        "    for s in tracts['Sample'].unique():\n",
        "        sample_tracts = tracts[tracts['Sample'] == s].copy()\n",
        "\n",
        "        sample_tracts = pr.PyRanges(sample_tracts)\n",
        "        merged_sample_tracts = sample_tracts.merge(strand=False)\n",
        "        sample_names = pd.Series(\n",
        "            data=[s]*len(merged_sample_tracts), name=\"Sample\")\n",
        "        merged_sample_tracts = merged_sample_tracts.insert(sample_names)\n",
        "\n",
        "        with open(bed_file, 'a') as f:\n",
        "            f.write(merged_sample_tracts.df.to_csv(\n",
        "                    sep=\"\\t\", header=False, index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"true-tract-example\"></a>\n",
        "We can obtain the true introgressed fragments in the tree-squence file `lr.training.ts` with the following codes:"
      ],
      "metadata": {
        "id": "3Rdc4fWJcHfW"
      },
      "id": "3Rdc4fWJcHfW"
    },
    {
      "cell_type": "code",
      "source": [
        "get_true_tracts(ts_file='examples/example.training.ts',\n",
        "                tgt_id='target', src_id='source', ploidy=2,\n",
        "                bed_file='examples/example.training.true.tracts.bed')"
      ],
      "metadata": {
        "id": "gfWnp5j4cH1O"
      },
      "id": "gfWnp5j4cH1O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The true introgressed fragments are stored in the file `lr.training.true.tracts.bed`, which is in the [BED](https://genome.ucsc.edu/FAQ/FAQformat.html#format1) format. We can view this file with the following shell command:"
      ],
      "metadata": {
        "id": "S56B6oavva3d"
      },
      "id": "S56B6oavva3d"
    },
    {
      "cell_type": "code",
      "source": [
        "!cat examples/example.training.true.tracts.bed"
      ],
      "metadata": {
        "id": "UjcsABBku460"
      },
      "id": "UjcsABBku460",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first column is the name of the simulated chromosome. The second column is the start position of an introgressed fragment in the genome, and the third column is the end position of an introgressed fragment in the genome. The fourth column is the name of the sample containing an introgressed fragment. For example, as shown above, the first haplotype of the individual `tsk_64` has an introgressed fragment ranging from the position 0 to the position 50,000, while the second haplotype of the individual `tsk_73` has an introgressed fragment starting at the position 0 and ending at the position 16,319.\n"
      ],
      "metadata": {
        "id": "6BjLqoWNt8H7"
      },
      "id": "6BjLqoWNt8H7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"task2\"></a>\n",
        "**Task 2:** Please use the `get_true_tracts()` function to extract all the true introgressed fragments in the simulated dataset from [Task 1](#task1)."
      ],
      "metadata": {
        "id": "lw4R6pzZNOLG"
      },
      "id": "lw4R6pzZNOLG"
    },
    {
      "cell_type": "code",
      "source": [
        "# Please implement your code here.\n"
      ],
      "metadata": {
        "id": "jiFEMkaFNp-X"
      },
      "id": "jiFEMkaFNp-X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "  <summary>\n",
        "    <font size=\"3\" color=\"darkgreen\">\n",
        "      <b>Click for hints</b>\n",
        "    </font>\n",
        "  </summary>\n",
        "\n",
        "  1. Again, implement a for-loop using `for i in range(100):` to wrap the following command from the above [example](#true-tract-example):\n",
        "  \n",
        "    ```\n",
        "    get_true_tracts(ts_file='examples/example.training.ts',\n",
        "                     tgt_id='target', src_id='source', ploidy=2,\n",
        "                     bed_file='examples/example.training.true.tracts.bed')\n",
        "    ```\n",
        "  2. Use Python f-string to modify the `ts_file` parameter from `ts_file='examples/example.training.ts'` to `ts_file=f'training/lr.training.{i}.ts'`, because our simulated data from [Task 1](#task1) are stored in the `training` folder with the prefix `lr.training.{i}`.\n",
        "  3. Also, change the `bed_file='examples/example.training.true.tracts.bed'` to `bed_file=f'training/lr.training.{i}.true.tracts.bed` to direct the output to the correct directory.\n",
        "\n",
        "  - <details>\n",
        "      <summary>\n",
        "        <font size=\"3\" color=\"darkblue\">\n",
        "          <b>Click for solutions</b>\n",
        "        </font>\n",
        "      </summary>\n",
        "\n",
        "    ```\n",
        "    for i in range(100):\n",
        "        get_true_tracts(ts_file=f'training/lr.training.{i}.ts',\n",
        "                        tgt_id='target', src_id='source', ploidy=2,\n",
        "                        bed_file=f'training/lr.training.{i}.true.tracts.bed')\n",
        "    ```\n",
        "  </details>\n",
        "</details>"
      ],
      "metadata": {
        "id": "E3Vk2NI8mi4Z"
      },
      "id": "E3Vk2NI8mi4Z"
    },
    {
      "cell_type": "markdown",
      "source": [
        "After obtaining the true introgressed fragments, we can label each simulated sequence as introgressed or non-introgressed based on these true introgressed fragments. Because machine learning models make predictions using category numbers, such as 0, 1, and 2, in classification problems, we will label a sequence as introgressed with 1, and a sequence as non-introgressed with 0. We have implemented a function `label_data()` below to label our simulated data according to a specified BED file containing the true introgressed fragments."
      ],
      "metadata": {
        "id": "xnN8a5-X6zQS"
      },
      "id": "xnN8a5-X6zQS"
    },
    {
      "cell_type": "code",
      "source": [
        "def label_data(true_tract_file: str, nref: int, ntgt: int, seq_len: int,\n",
        "               ploidy: int, intro_prop: float, not_intro_prop: float,\n",
        "               output: str) -> None:\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Labels each simulated genome with the true introgressed fragments.\n",
        "\n",
        "    Arguments:\n",
        "        true_tract_file str: Name of the BED file containing\n",
        "                             the true introgressed fragments.\n",
        "        nref int: Number of individuals sampled from the reference population.\n",
        "        ntgt int: Number of individuals sampled from the target population.\n",
        "        seq_len int: Length of the simulated sequence.\n",
        "        ploidy int: Ploidy of the simulated genome.\n",
        "        intro_prop float: Proportion that determines a fragment as introgressed.\n",
        "        not_intro_prop float: Proportion that determinse a fragment as\n",
        "                              non-introgressed.\n",
        "        output str: Name of the output file.\n",
        "\n",
        "    Returns:\n",
        "        None.\n",
        "    \"\"\"\n",
        "    def _add_label(row, intro_prop, not_intro_prop):\n",
        "        if row['prop'] > intro_prop: return 1.0\n",
        "        elif row['prop'] < not_intro_prop: return 0.0\n",
        "        else: return -1.0\n",
        "\n",
        "    label_df = pd.DataFrame(columns=['chrom', 'start', 'end', 'sample'])\n",
        "    for i in range(nref, nref+ntgt):\n",
        "        for p in range(ploidy):\n",
        "            label_df.loc[len(label_df.index)] = [\n",
        "                1, 0, seq_len, f'tsk_{i}_{p+1}'\n",
        "            ]\n",
        "\n",
        "    try:\n",
        "        true_tract_df = pd.read_csv(true_tract_file, sep=\"\\t\", header=None)\n",
        "    except pd.errors.EmptyDataError:\n",
        "        label_df['label'] = 0.0\n",
        "    else:\n",
        "        true_tract_df.columns = ['chrom', 'start', 'end', 'sample']\n",
        "        true_tract_df['len'] = true_tract_df['end'] - true_tract_df['start']\n",
        "        true_tract_df = true_tract_df.groupby(\n",
        "            by=['sample']\n",
        "        )['len'].sum().reset_index()\n",
        "        true_tract_df['prop'] = true_tract_df['len'] / seq_len\n",
        "        true_tract_df['label'] = true_tract_df.apply(\n",
        "            lambda row: _add_label(row, intro_prop, not_intro_prop), axis=1)\n",
        "        label_df = label_df.merge(true_tract_df.drop(columns=['len', 'prop']),\n",
        "                                  left_on=['sample'], right_on=['sample'],\n",
        "                                  how='left').fillna(0)\n",
        "    finally:\n",
        "        label_df['label'] = label_df['label'].astype('int8')\n",
        "        label_df.to_csv(output, sep=\"\\t\", index=False)"
      ],
      "metadata": {
        "id": "o8iP24JHxk-j"
      },
      "id": "o8iP24JHxk-j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"label-example\"></a>\n",
        "Now we can label our simulated data using the `label_data()` function and the true introgressed fragments in `lr.training.true.tracts.bed`."
      ],
      "metadata": {
        "id": "HoU4F2CwD5JV"
      },
      "id": "HoU4F2CwD5JV"
    },
    {
      "cell_type": "code",
      "source": [
        "label_data(true_tract_file='examples/example.training.true.tracts.bed',\n",
        "           nref=50, ntgt=50, seq_len=50000, ploidy=2,\n",
        "           intro_prop=0.7, not_intro_prop=0.3,\n",
        "           output='examples/example.training.labels')"
      ],
      "metadata": {
        "id": "HhHsISfZD5nc"
      },
      "id": "HhHsISfZD5nc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can examine the labels of the first 50 samples with the following shell command:"
      ],
      "metadata": {
        "id": "ZvJ69oVjUAL_"
      },
      "id": "ZvJ69oVjUAL_"
    },
    {
      "cell_type": "code",
      "source": [
        "!head -51 examples/example.training.labels"
      ],
      "metadata": {
        "id": "0AWoevnHMjJH"
      },
      "id": "0AWoevnHMjJH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To classify these samples, we employ two parameters in the `labelling_data()` function: `intro_prop` and `not_intro_prop`. These parameters help determine the labels based on the proportion of the length of the introgressed fragment to the total length of the simulated sequence. Besides the classes `0` and `1`, we introduce an additional class `-1` to account for variations in the length of introgressed fragments across different simulated genomes:\n",
        "\n",
        "- A sample is labeled as `1` if the proportion is larger than `intro_prop`.\n",
        "- A sample is labeled as `0` if the proportion is less than `not_intro_prop`.\n",
        "- A sample is labeled as `-1` if the proportion falls between `intro_prop` and `not_intro_prop`.\n",
        "\n",
        "For example, the introgressed fragment in `tsk_64_1` is 50,000 bp long, identical to the length of the simulated sequence, resulting in a proportion of 1. This exceeds the threshold of `intro_prop=0.7`, thus `tsk_64_1` is labeled as `1`. Conversely, `tsk_73_2` has an introgressed fragment measuring 16,319 bp in a 50,000 bp sequence, yielding a proportion of approximately 0.32658. This value lies between `intro_prop=0.7` and `not_intro_prop=0.3`, so `tsk_73_2` is labeled as `-1`.\n",
        "We will discard those data with the class `-1` later, because logistic regression is best suited for binary classification."
      ],
      "metadata": {
        "id": "4W2ptyAxS4ie"
      },
      "id": "4W2ptyAxS4ie"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"task3\"></a>\n",
        "**Task 3:** Please use the `label_data()` function to label the simulated data from [Task 1](#task1)."
      ],
      "metadata": {
        "id": "12sl7JABNWoW"
      },
      "id": "12sl7JABNWoW"
    },
    {
      "cell_type": "code",
      "source": [
        "# Please implement your code here.\n"
      ],
      "metadata": {
        "id": "wq4c7vrOS7am"
      },
      "id": "wq4c7vrOS7am",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "  <summary>\n",
        "    <font size=\"3\" color=\"darkgreen\">\n",
        "      <b>Click for hints</b>\n",
        "    </font>\n",
        "  </summary>\n",
        "\n",
        "  1. Use a for-loop and the command from [above](#label-example):\n",
        "  \n",
        "    ```\n",
        "    label_data(true_tract_file='examples/example.training.true.tracts.bed',\n",
        "                nref=50, ntgt=50, seq_len=50000, ploidy=2,\n",
        "                intro_prop=0.7, not_intro_prop=0.3,\n",
        "                output='examples/example.training.labels')\n",
        "    ```\n",
        "  2. Use Python f-string to change the `true_tract_file` parameter to those BED files created in [Task 2](#task2) and the `output` parameter to direct the output files to the `training` folder with the prefix `lr.training.{i}`.\n",
        "\n",
        "  - <details>\n",
        "      <summary>\n",
        "        <font size=\"3\" color=\"darkblue\">\n",
        "          <b>Click for solutions</b>\n",
        "        </font>\n",
        "      </summary>\n",
        "\n",
        "    ```\n",
        "    for i in range(100):\n",
        "        label_data(true_tract_file=f'training/lr.training.{i}.true.tracts.bed',\n",
        "                   nref=50, ntgt=50, seq_len=50000, ploidy=2,\n",
        "                   intro_prop=0.7, not_intro_prop=0.3,\n",
        "                   output=f'training/lr.training.{i}.labels')\n",
        "    ```\n",
        "  </details>\n",
        "</details>"
      ],
      "metadata": {
        "id": "CWMlQUXPzfw_"
      },
      "id": "CWMlQUXPzfw_"
    },
    {
      "cell_type": "markdown",
      "id": "f447f217",
      "metadata": {
        "id": "f447f217"
      },
      "source": [
        "### Calculating Input Features"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To effectively utilize logistic regression for identifying introgressed fragments, it is crucial to convert the genotypes in simulated genomes into quantitative statistics or features. For this purpose, below we have provided two functions: `cal_dist()` and `cal_mut_num()`, each serving a distinct role in calculating input features:\n",
        "\n",
        "1. Function `cal_dist()`: This function is designed to compute the pairwise [Euclidean distances](https://en.wikipedia.org/wiki/Euclidean_distance) between genotype matrices. Its primary use is to estimate the distances in two scenarios:\n",
        "    - Between genomes sampled from the reference population and those from the target population.\n",
        "    - Within the genomes belonging to the target population.\n",
        "\n",
        "  These distance measurements are crucial for assessing genetic similarities and differences, aiding in the detection of introgressed fragments.\n",
        "\n",
        "2. Function `cal_mut_num()`: This function focuses on the enumeration of mutations, distinguishing between two types:\n",
        "    - Private Mutations: These are exclusive mutations found only in the target population. Their identification is important for understanding unique genetic variations, especially for those mutations originated from the source population.\n",
        "    - Total Mutations: This category includes all mutations observed in either the target or the reference population. Counting total mutations provides a comprehensive view of the genetic variability across populations.\n",
        "\n",
        "Both functions are instrumental in transforming raw genetic data into analyzable metrics, which are then utilized in logistic regression models to detect introgressed fragments."
      ],
      "metadata": {
        "id": "YzvoCbz1dqtu"
      },
      "id": "YzvoCbz1dqtu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a928bb4",
      "metadata": {
        "id": "5a928bb4"
      },
      "outputs": [],
      "source": [
        "def cal_dist(gt1: np.ndarray, gt2: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Calculates pairswise Euclidean distances between two genotype matrices.\n",
        "\n",
        "    Arguments:\n",
        "        gt1 numpy.ndarray: Genotype matrix 1.\n",
        "        gt2 numpy.ndarray: Genotype matrix 2.\n",
        "\n",
        "    Returns:\n",
        "        dists numpy.ndarray: Distances estimated.\n",
        "    \"\"\"\n",
        "    dists = distance_matrix(np.transpose(gt2), np.transpose(gt1))\n",
        "    dists.sort()\n",
        "\n",
        "    return dists\n",
        "\n",
        "\n",
        "def cal_mut_num(ref_gt: np.ndarray, tgt_gt: np.ndarray,\n",
        "                mut_type: str) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Calculates number of private or total mutations in a sample.\n",
        "\n",
        "    Arguments:\n",
        "        ref_gt numpy.ndarray: Genotype matrix from the reference population.\n",
        "        tgt_gt numpy.ndarray: Genotype matrix from the target population.\n",
        "        mut_type str: Type of mutations. Private or total.\n",
        "\n",
        "    Returns:\n",
        "        mut_num numpy.ndarray: Numbers of mutations.\n",
        "    \"\"\"\n",
        "    counts = np.sum(ref_gt, axis=1)\n",
        "    counts = np.reshape(counts, (counts.shape[0],1))\n",
        "\n",
        "    if mut_type == 'private':\n",
        "        mut_num = np.sum((tgt_gt>0)*(counts==0), axis=0)\n",
        "    if mut_type == 'total':\n",
        "        mut_num = np.sum((tgt_gt>0), axis=0) + np.sum((tgt_gt==0)*(counts>0),\n",
        "                                                       axis=0)\n",
        "\n",
        "    return mut_num\n",
        "\n",
        "\n",
        "def cal_features(ref_gts: np.ndarray, tgt_gts: np.ndarray,\n",
        "                     pos: np.ndarray) -> dict:\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Calculates feature vectors from genotype matrixes.\n",
        "\n",
        "    Arguments:\n",
        "        ref_gts numpy.ndarray: Genotype matrix from the reference\n",
        "                                   population.\n",
        "        tgt_gts numpy.ndarray: Genotype matrix from the target population.\n",
        "        pos numpy.ndarray: Positions of variants.\n",
        "\n",
        "    Returns:\n",
        "        res dict: Estimated input feature vectors.\n",
        "    \"\"\"\n",
        "    variants_not_in_ref = np.sum(ref_gts, axis=1) == 0\n",
        "    sub_ref_gts = ref_gts[variants_not_in_ref]\n",
        "    sub_tgt_gts = tgt_gts[variants_not_in_ref]\n",
        "    sub_pos = pos[variants_not_in_ref]\n",
        "\n",
        "    ref_dists = cal_dist(ref_gts, tgt_gts)\n",
        "    tgt_dists = cal_dist(tgt_gts, tgt_gts)\n",
        "\n",
        "    res = dict()\n",
        "    res['ttl_mut_nums'] = cal_mut_num(ref_gts, tgt_gts, mut_type='total')\n",
        "    res['pvt_mut_nums'] = cal_mut_num(sub_ref_gts, sub_tgt_gts,\n",
        "                                      mut_type='private')\n",
        "\n",
        "    res['ref_dists'] = ref_dists\n",
        "    res['min_ref_dists'] = np.min(ref_dists, axis=1)\n",
        "    res['max_ref_dists'] = np.max(ref_dists, axis=1)\n",
        "    res['mean_ref_dists'] = np.mean(ref_dists, axis=1)\n",
        "    res['median_ref_dists'] = np.median(ref_dists, axis=1)\n",
        "    res['var_ref_dists'] = np.var(ref_dists, axis=1)\n",
        "    res['skew_ref_dists'] = scipy.stats.skew(ref_dists, axis=1)\n",
        "    res['skew_ref_dists'][np.isnan(res['skew_ref_dists'])] = 0\n",
        "    res['kurtosis_ref_dists'] = scipy.stats.kurtosis(ref_dists, axis=1)\n",
        "    res['kurtosis_ref_dists'][np.isnan(res['kurtosis_ref_dists'])] = 0\n",
        "\n",
        "    res['tgt_dists'] = tgt_dists\n",
        "    res['min_tgt_dists'] = np.min(tgt_dists, axis=1)\n",
        "    res['max_tgt_dists'] = np.max(tgt_dists, axis=1)\n",
        "    res['mean_tgt_dists'] = np.mean(tgt_dists, axis=1)\n",
        "    res['median_tgt_dists'] = np.median(tgt_dists, axis=1)\n",
        "    res['var_tgt_dists'] = np.var(tgt_dists, axis=1)\n",
        "    res['skew_tgt_dists'] = scipy.stats.skew(tgt_dists, axis=1)\n",
        "    res['skew_tgt_dists'][np.isnan(res['skew_tgt_dists'])] = 0\n",
        "    res['kurtosis_tgt_dists'] = scipy.stats.kurtosis(tgt_dists, axis=1)\n",
        "    res['kurtosis_tgt_dists'][np.isnan(res['kurtosis_tgt_dists'])] = 0\n",
        "\n",
        "    return res"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also implemented several helper functions below to convert the genotype data from our simulation into several features estimated with the above two functions."
      ],
      "metadata": {
        "id": "SlN1pkLWWOsI"
      },
      "id": "SlN1pkLWWOsI"
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import *\n",
        "def preprocess(vcf_file: str, ref_ind_file: str, tgt_ind_file: str,\n",
        "               ploidy: int, output_dir: str, output_prefix: str,\n",
        "               win_len: int, win_step: int) -> None:\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Processes genotype data.\n",
        "\n",
        "    Arguments:\n",
        "        vcf_file str: Name of the VCF file containing genotype data.\n",
        "        ref_ind_file str: Name of the file containing sample information\n",
        "                          from the reference population.\n",
        "        tgt_ind_file str: Name of the file containing sample information\n",
        "                          from the target population.\n",
        "        ploidy int: Ploidy of genomes.\n",
        "        output_dir str: Directory storing the output files.\n",
        "        output_prefix str: Prefix of the output files.\n",
        "        win_len int: Length of sliding windows.\n",
        "        win_step int: Step size of sliding windows.\n",
        "\n",
        "    Returns:\n",
        "        None.\n",
        "    \"\"\"\n",
        "    ref_data, ref_samples, tgt_data, tgt_samples = read_data(\n",
        "        vcf_file, ref_ind_file, tgt_ind_file\n",
        "    )\n",
        "\n",
        "    for c in tgt_data.keys():\n",
        "        windows = create_windows(tgt_data[c]['POS'], c, win_step, win_len)\n",
        "\n",
        "    res = []\n",
        "    for w in windows:\n",
        "        chr_name, start, end = w\n",
        "        ref_gts = ref_data[chr_name]['GT']\n",
        "        tgt_gts = tgt_data[chr_name]['GT']\n",
        "        pos = tgt_data[chr_name]['POS']\n",
        "        idx = (pos>start)*(pos<=end)\n",
        "        sub_ref_gts = ref_gts[idx]\n",
        "        sub_tgt_gts = tgt_gts[idx]\n",
        "        sub_pos = pos[idx]\n",
        "        res.append([chr_name, start, end, cal_features(\n",
        "            sub_ref_gts, sub_tgt_gts, sub_pos\n",
        "        )])\n",
        "\n",
        "    output(res=res, tgt_samples=tgt_samples, ploidy=2,\n",
        "           output_dir=output_dir, output_prefix=output_prefix)"
      ],
      "metadata": {
        "id": "3fXQLB-NWPKf"
      },
      "id": "3fXQLB-NWPKf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"preprocess-example\"></a>\n",
        "We then can apply the `preprocess()` function to process our simulated data in the `example` folder, as shown below:"
      ],
      "metadata": {
        "id": "Sfm9re50ne8i"
      },
      "id": "Sfm9re50ne8i"
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess(vcf_file='examples/example.training.vcf',\n",
        "           ref_ind_file='examples/example.training.ref.ind.list',\n",
        "           tgt_ind_file='examples/example.training.tgt.ind.list',\n",
        "           ploidy=2, output_dir='examples',\n",
        "           output_prefix='example.training', win_len=50000, win_step=50000)"
      ],
      "metadata": {
        "id": "AvFl_GfVTNO4"
      },
      "id": "AvFl_GfVTNO4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After processing our simulated genotype data, we can examine the features of the first ten samples. Each row contains statistics or features related to a specific haplotype. This row can be referred to as the feature vector, with its elements representing individual features."
      ],
      "metadata": {
        "id": "LWiQvDjZW0a5"
      },
      "id": "LWiQvDjZW0a5"
    },
    {
      "cell_type": "code",
      "source": [
        "!head -11 examples/example.training.features"
      ],
      "metadata": {
        "id": "SeSehl4Xw42y"
      },
      "id": "SeSehl4Xw42y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 4:** Please use the `preprocess()` function to calculate features for the simulated data from [Task 1](#task1)."
      ],
      "metadata": {
        "id": "ioF1j9RZWSDv"
      },
      "id": "ioF1j9RZWSDv"
    },
    {
      "cell_type": "code",
      "source": [
        "# Please implement your code here.\n"
      ],
      "metadata": {
        "id": "vjs0LOY4WVMf"
      },
      "id": "vjs0LOY4WVMf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "  <summary>\n",
        "    <font size=\"3\" color=\"darkgreen\">\n",
        "      <b>Click for hints</b>\n",
        "    </font>\n",
        "  </summary>\n",
        "\n",
        "  1. Use a for-loop and follow [the above command](#preprocess-example):\n",
        "  \n",
        "    ```\n",
        "    preprocess(vcf_file='examples/example.training.vcf',\n",
        "                ref_ind_file='examples/example.training.ref.ind.list',\n",
        "                tgt_ind_file='examples/example.training.tgt.ind.list',\n",
        "                ploidy=2, output_dir='examples',\n",
        "                output_prefix='example.training', win_len=50000, win_step=50000)\n",
        "    ```\n",
        "  2. Alter the `vcf_file`, `ref_ind_file`, `tgt_ind_file` parameters with those corresponding files created in [Task 1](#task1).\n",
        "  3. Adjust the `output_dir` and `output_prefix` parameters: the output directory is the `training` folder, and the output prefix is `lr.training.{i}`\n",
        "  - <details>\n",
        "      <summary>\n",
        "        <font size=\"3\" color=\"darkblue\">\n",
        "          <b>Click for solutions</b>\n",
        "        </font>\n",
        "      </summary>\n",
        "\n",
        "    ```\n",
        "    for i in range(100):\n",
        "        preprocess(vcf_file=f'training/lr.training.{i}.vcf',\n",
        "                    ref_ind_file=f'training/lr.training.{i}.ref.ind.list',\n",
        "                    tgt_ind_file=f'training/lr.training.{i}.tgt.ind.list',\n",
        "                    ploidy=2, output_dir='training',\n",
        "                    output_prefix=f'lr.training.{i}', win_len=50000, win_step=50000)\n",
        "    ```\n",
        "  </details>\n",
        "</details>"
      ],
      "metadata": {
        "id": "XKYQk3JH8kdV"
      },
      "id": "XKYQk3JH8kdV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "After transforming all the simulated data into feature vectors, we can merge these vectors with their respective labels. This combination creates the training dataset `lr.training.all.labelled.features` in the `training` folder, which is essential for developing our logistic regression model aimed at identifying ghost introgressed fragments."
      ],
      "metadata": {
        "id": "KDDVk6AyXX4S"
      },
      "id": "KDDVk6AyXX4S"
    },
    {
      "cell_type": "code",
      "source": [
        "!head -1 training/lr.training.0.features | \\\n",
        "    awk '{print $0\"\\tlabel\"}'> training/lr.training.all.labelled.features\n",
        "!for ((i=0;i<100;i++)) do \\\n",
        "    paste <(sed '1d' training/lr.training.$i.features) \\\n",
        "          <(sed '1d' training/lr.training.$i.labels | awk '{print $NF}') \\\n",
        "          >> training/lr.training.all.labelled.features; \\\n",
        " done\n",
        "!head -11 training/lr.training.all.labelled.features"
      ],
      "metadata": {
        "id": "C457qZ0_wXZ-"
      },
      "id": "C457qZ0_wXZ-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the training dataset `lr.training.all.labelled.features`, along with various features, we append a label to the end of each feature vector. This label indicates whether a sample is an introgressed fragment. We can analyze the distribution of feature vectors across the different classes:"
      ],
      "metadata": {
        "id": "kD_Hg0ZBcCLw"
      },
      "id": "kD_Hg0ZBcCLw"
    },
    {
      "cell_type": "code",
      "source": [
        "!awk '$NF==0' training/lr.training.all.labelled.features | \\\n",
        " awk 'END{print \"Number of feature vectors belonging to class 0: \"NR}'\n",
        "!awk '$NF==1' training/lr.training.all.labelled.features | \\\n",
        " awk 'END{print \"Number of feature vectors belonging to class 1: \"NR}'\n",
        "!awk '$NF==-1' training/lr.training.all.labelled.features | \\\n",
        " awk 'END{print \"Number of feature vectors belonging to class -1: \"NR}'"
      ],
      "metadata": {
        "id": "71dHn7MezlxK"
      },
      "id": "71dHn7MezlxK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"modelling\"></a>\n",
        "## Creating a Logistic Regression Model"
      ],
      "metadata": {
        "id": "aj7nwrg8Sru_"
      },
      "id": "aj7nwrg8Sru_"
    },
    {
      "cell_type": "markdown",
      "id": "5373a361",
      "metadata": {
        "id": "5373a361"
      },
      "source": [
        "<a name=\"training\"></a>\n",
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are ready to train our first machine learning model with our training dataset `lr.training.all.labelled.features`. Here, we will use the [Logistic Regression classifier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) from [scikit-learn](https://scikit-learn.org/stable/index.html), which is a popular Python package for machine learning."
      ],
      "metadata": {
        "id": "qAsvyX3Om8Ak"
      },
      "id": "qAsvyX3Om8Ak"
    },
    {
      "cell_type": "code",
      "source": [
        "def train(feature_file: str, model_file: str) -> None:\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Function for training of the sklearn logistic classification.\n",
        "\n",
        "    Arguments:\n",
        "        feature_file str: Filename of the feature file for training.\n",
        "        model_file str: Filename of the output model.\n",
        "\n",
        "    Returns:\n",
        "        None.\n",
        "    \"\"\"\n",
        "    feature_df = pd.read_csv(feature_file, sep=\"\\t\")\n",
        "\n",
        "    model = LogisticRegression(solver=\"newton-cg\", penalty=None, max_iter=10000)\n",
        "    # Remove feature vectors with label -1\n",
        "    feature_df = feature_df[feature_df['label'] != -1]\n",
        "    labels = feature_df['label']\n",
        "    data = feature_df.drop(\n",
        "        columns=['chrom', 'start', 'end', 'sample', 'label']).values\n",
        "\n",
        "    model.fit(data, labels.astype(int))\n",
        "\n",
        "    os.makedirs(os.path.dirname(model_file), exist_ok=True)\n",
        "    pickle.dump(model, open(model_file, \"wb\"))"
      ],
      "metadata": {
        "id": "Zc-fgzHTxdLd"
      },
      "id": "Zc-fgzHTxdLd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We provide the training dataset, `lr.training.all.labelled.features`, from Task 4 to the `train()` function and store the resulting model `logistic.regression.model` in the `models` folder:"
      ],
      "metadata": {
        "id": "cuO3uQdPoTgJ"
      },
      "id": "cuO3uQdPoTgJ"
    },
    {
      "cell_type": "code",
      "source": [
        "train(feature_file='training/lr.training.all.labelled.features',\n",
        "      model_file='models/logistic.regression.model')"
      ],
      "metadata": {
        "id": "y88IK3LT0RFy"
      },
      "id": "y88IK3LT0RFy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that we exclude those feature vectors labelled as `-1` in the `train()` function. This exclusion is due to the fact that we are applying logistic regression for binary classification, focusing solely on predicting classes `0` and `1`. We can check our model file with the following:"
      ],
      "metadata": {
        "id": "3mYrUSYBqLXP"
      },
      "id": "3mYrUSYBqLXP"
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l models"
      ],
      "metadata": {
        "id": "FOROX_5XqMBP"
      },
      "id": "FOROX_5XqMBP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d2cbc3d8",
      "metadata": {
        "id": "d2cbc3d8"
      },
      "source": [
        "<a name=\"test\"></a>\n",
        "### Test"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"prediction\"></a>\n",
        "#### Prediction"
      ],
      "metadata": {
        "id": "B5X4RrZWCf5H"
      },
      "id": "B5X4RrZWCf5H"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once we obtain our machine learning model, we can apply it for making predictions with new data. First, we need to download some test data, which should be different from the training data:"
      ],
      "metadata": {
        "id": "jPYuT2jIoIiV"
      },
      "id": "jPYuT2jIoIiV"
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir test\n",
        "!wget -c https://huggingface.co/datasets/xin-huang/pgml/resolve/dev/Section_02/sim.test.features\n",
        "!wget -c https://huggingface.co/datasets/xin-huang/pgml/resolve/dev/Section_02/sim.test.true.tracts.bed\n",
        "!mv sim.test.features test\n",
        "!mv sim.test.true.tracts.bed test"
      ],
      "metadata": {
        "id": "6VEzV0eDSqIB"
      },
      "execution_count": null,
      "outputs": [],
      "id": "6VEzV0eDSqIB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We downloaded two files in the `test` folder:"
      ],
      "metadata": {
        "id": "dWMu2LU4uwWd"
      },
      "id": "dWMu2LU4uwWd"
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l ./test"
      ],
      "metadata": {
        "id": "xkpHxBqOvdQF"
      },
      "id": "xkpHxBqOvdQF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `sim.test.features` file contains feature vectors for use in predictions, while the `sim.test.true.tracts.bed` file holds the ground truth data for introgressed fragments. This data will be utilized later to evaluate the performance of our model."
      ],
      "metadata": {
        "id": "Qs13FO5jv8ev"
      },
      "id": "Qs13FO5jv8ev"
    },
    {
      "cell_type": "code",
      "source": [
        "def infer(feature_file: str, model_file: str, output: str) -> None:\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Function for inference using the sklearn logistic classifciation.\n",
        "\n",
        "    Arguments:\n",
        "        feature_file str: Filename of the feature file for inference.\n",
        "        model_file str: Filename of the trained logistic regression model.\n",
        "        prediction_file str: Filename of the output predictions.\n",
        "\n",
        "    Returns:\n",
        "        None.\n",
        "    \"\"\"\n",
        "    with open(model_file, 'rb') as f:\n",
        "        model = pickle.load(f)\n",
        "\n",
        "    feature_df = pd.read_csv(feature_file, sep=\"\\t\")\n",
        "    data = feature_df.drop(columns=['chrom', 'start', 'end', 'sample']).values\n",
        "\n",
        "    predictions = model.predict_proba(data)\n",
        "\n",
        "    classes = model.classes_\n",
        "    columns = ['chrom', 'start', 'end', 'sample']\n",
        "    for i in range(len(classes)):\n",
        "        feature_df[f'class_{classes[i]}_prob'] = predictions[:,i]\n",
        "        columns.append(f'class_{classes[i]}_prob')\n",
        "\n",
        "    feature_df = feature_df[columns]\n",
        "    feature_df.sort_values(\n",
        "        by=['sample', 'chrom', 'start', 'end']\n",
        "    ).to_csv(output, sep=\"\\t\", index=False)"
      ],
      "metadata": {
        "id": "-jEMWBUz0AvT"
      },
      "id": "-jEMWBUz0AvT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can predict the label of each feature vectors in the `sim.test.features` file with the model we have trained:"
      ],
      "metadata": {
        "id": "DKBLQpeeydQJ"
      },
      "id": "DKBLQpeeydQJ"
    },
    {
      "cell_type": "code",
      "source": [
        "infer(feature_file='test/sim.test.features',\n",
        "      model_file='models/logistic.regression.model',\n",
        "      output='test/sim.test.predictions')"
      ],
      "metadata": {
        "id": "AiM9D_YevLyJ"
      },
      "id": "AiM9D_YevLyJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can examine our predictions for the first ten fragments:"
      ],
      "metadata": {
        "id": "z0QDOlzQz4SU"
      },
      "id": "z0QDOlzQz4SU"
    },
    {
      "cell_type": "code",
      "source": [
        "!head -11 test/sim.test.predictions"
      ],
      "metadata": {
        "id": "q5I72v9FvPqe"
      },
      "id": "q5I72v9FvPqe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each fragment, we predict two probabilities: one is the probability of the fragment belonging to class `0` (or not introgressed), and the other is the probability of the fragment belonging to class `1` (or introgressed).\n",
        "\n",
        "To determine whether a fragment belongs to class `0` or `1`, we need to provide a cutoff. If the probability of the fragment belonging to class `1` exceeds this cutoff, then we assign it as an introgressed fragment. Otherwise, we consider it as a non-introgressed fragment. For this purpose, we have implemented the following fucntion:"
      ],
      "metadata": {
        "id": "xxNkt5iB0MO8"
      },
      "id": "xxNkt5iB0MO8"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_inferred_tracts(prediction_file: str, cutoff: float,\n",
        "                        output: str) -> None:\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Obtains inferred introgressed fragments from predictions.\n",
        "\n",
        "    Arguments:\n",
        "        prediction_file str: Name of the file containing predictions from\n",
        "                             a model.\n",
        "        cutoff float: Probability threshold to determine whether a fragment\n",
        "                      is introgressed or not.\n",
        "        output str: Name of the output file storing the inferred introgressed\n",
        "                    fragments.\n",
        "\n",
        "    Returns:\n",
        "        None.\n",
        "    \"\"\"\n",
        "    prediction_df = pd.read_csv(prediction_file, sep=\"\\t\")\n",
        "    inferred_tracts = prediction_df[prediction_df['class_1_prob'] > cutoff]\n",
        "    inferred_tracts_wo_probs = inferred_tracts.drop(\n",
        "        columns=['class_0_prob', 'class_1_prob']\n",
        "    )\n",
        "    inferred_tracts_wo_probs.rename(\n",
        "        columns={'chrom': 'Chromosome', 'start': 'Start',\n",
        "                 'end': 'End', 'sample': 'Sample'},\n",
        "    inplace=True)\n",
        "    inferred_tracts = pr.PyRanges(inferred_tracts_wo_probs).merge(by='Sample')\n",
        "    inferred_tracts.to_csv(output, sep=\"\\t\", header=False)"
      ],
      "metadata": {
        "id": "2NFqz_Bd3xog"
      },
      "id": "2NFqz_Bd3xog",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given the `cutoff=0.9`, we can obtain the inferred introgressed fragments from our predictions:"
      ],
      "metadata": {
        "id": "9YbaYF395tT7"
      },
      "id": "9YbaYF395tT7"
    },
    {
      "cell_type": "code",
      "source": [
        "get_inferred_tracts(prediction_file='test/sim.test.predictions', cutoff=0.9,\n",
        "                    output=f'test/sim.test.cutoff0.9.inferred.tracts.bed')"
      ],
      "metadata": {
        "id": "vpSexg-uj7c1"
      },
      "id": "vpSexg-uj7c1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can view the first ten inferred introgressed fragments:"
      ],
      "metadata": {
        "id": "2s6XgTHB7if2"
      },
      "id": "2s6XgTHB7if2"
    },
    {
      "cell_type": "code",
      "source": [
        "!head -10 test/sim.test.cutoff0.9.inferred.tracts.bed"
      ],
      "metadata": {
        "id": "cNHNG00B5zqh"
      },
      "id": "cNHNG00B5zqh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"evaluation\"></a>\n",
        "#### Evaluation\n",
        "\n"
      ],
      "metadata": {
        "id": "cPn5ig8yFRUO"
      },
      "id": "cPn5ig8yFRUO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the true framgents in `sim.test.true.tracts.bed` and inferred fragments, we can quantify how good our model is. Here, we will use two metrics — **precsion** and **recall** — to measure the performance of our model:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "Precsion &= \\frac{TP}{TP+FP} \\\\\n",
        "Recall &= \\frac{TP}{TP+FN} \\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "where\n",
        "\n",
        "- TP: Number of True Positive instances.\n",
        "- FP: Number of False Positive instances.\n",
        "- FN: Number of False Negative instances.\n",
        "\n",
        "More specifically, we define the True Positive, False Positive, and False Negative as shown in the following figure:\n",
        "\n",
        "![metrics.png](data:image/png;base64,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)\n",
        "\n",
        "Here, we compare the inferred introgressed fragment to the true introgressed fragment. We use the length of their overlap as the True Positive ($TP$) measurement. Consequently, the total length of the inferred introgressed fragments corresponds to the sum of True Positives and False Positives ($TP + FP$). Similarly, the total length of the true introgressed fragments is the sum of True Positives and False Negatives ($TP + FN$). Therefore,\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "Precsion &= \\frac{\\text{Length of the overlap}}{\\text{Length of the inferred introgressed fragment}} \\\\\n",
        "Recall &= \\frac{\\text{Length of the overlap}}{\\text{Length of the true introgressed fragment}} \\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "In simpler terms, **precision** indicates the proportion of inferred introgressed fragments that are actually true. On the other hand, **recall** measures the extent to which true introgressed fragments are correctly identified within the entire dataset ([Huang et al. 2024](https://doi.org/10.1038/s41576-023-00636-3))."
      ],
      "metadata": {
        "id": "UjtXD_4gOh26"
      },
      "id": "UjtXD_4gOh26"
    },
    {
      "cell_type": "code",
      "source": [
        "def cal_pr(ntrue_tracts: int, ninferred_tracts: int,\n",
        "           ntrue_positives: int) -> tuple[float, float]:\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Calculates precision and recall.\n",
        "\n",
        "    Arguments:\n",
        "        ntrue_tracts int: Length of true introgressed fragments.\n",
        "        ninferred_tracts int: Length of inferred introgressed fragments.\n",
        "        ntrue_positives int: Length of fragments belonging to true positives.\n",
        "\n",
        "    Returns:\n",
        "        precision float: Estimated precision.\n",
        "        recall float: Estimated recall.\n",
        "    \"\"\"\n",
        "    if float(ninferred_tracts) == 0: precision = np.nan\n",
        "    else: precision = ntrue_positives / float(ninferred_tracts) * 100\n",
        "    if float(ntrue_tracts) == 0: recall = np.nan\n",
        "    else: recall = ntrue_positives / float(ntrue_tracts) * 100\n",
        "\n",
        "    return precision, recall"
      ],
      "metadata": {
        "id": "kLMN36xv5-Yn"
      },
      "id": "kLMN36xv5-Yn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have implemented the `evaluate()` function below to estimate the precision and recall from the true fragment file and the inferred fragment file."
      ],
      "metadata": {
        "id": "7LTuOAVyUqWZ"
      },
      "id": "7LTuOAVyUqWZ"
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(true_tract_file: str, inferred_tract_file: str, cutoff: float,\n",
        "             output: str) -> None:\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Evaluates model performance with precision and recall.\n",
        "\n",
        "    Arguments:\n",
        "        true_tract_file str: Name of the file containing true fragments.\n",
        "        inferred_tract_file str: Name of the file containing inferred fragments\n",
        "        cutoff float: Probability threshold to determine whether a fragment\n",
        "                      is introgressed or not.\n",
        "        output str: Name of the output file storing the model performance.\n",
        "\n",
        "    Returns:\n",
        "        None.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        true_tracts = pd.read_csv(\n",
        "            true_tract_file, sep=\"\\t\", header=None,\n",
        "            names=['Chromosome', 'Start', 'End', 'Sample']\n",
        "        )\n",
        "    except pd.errors.EmptyDataError:\n",
        "        true_tracts_samples = []\n",
        "    else:\n",
        "        true_tracts_samples = true_tracts['Sample'].unique()\n",
        "        true_tracts = pr.PyRanges(true_tracts).merge(by='Sample')\n",
        "\n",
        "    try:\n",
        "        inferred_tracts = pd.read_csv(\n",
        "            inferred_tract_file, sep=\"\\t\", header=None,\n",
        "            names=['Chromosome', 'Start', 'End', 'Sample']\n",
        "        )\n",
        "    except pd.errors.EmptyDataError:\n",
        "        inferred_tracts_samples = []\n",
        "    else:\n",
        "        inferred_tracts_samples = inferred_tracts['Sample'].unique()\n",
        "        inferred_tracts = pr.PyRanges(inferred_tracts).merge(by='Sample')\n",
        "\n",
        "    res = pd.DataFrame(columns=[\n",
        "        'Sample', 'Cutoff', 'Precision', 'Recall', 'True_tracts_length',\n",
        "        'Inferred_tracts_length', 'Overlapped_length'])\n",
        "\n",
        "    sum_ntrue_tracts = 0\n",
        "    sum_ninferred_tracts = 0\n",
        "    sum_ntrue_positives = 0\n",
        "\n",
        "    for s in np.intersect1d(true_tracts_samples, inferred_tracts_samples):\n",
        "        ind_true_tracts = true_tracts[\n",
        "            true_tracts.Sample == s\n",
        "        ].merge(by='Sample')\n",
        "        ind_inferred_tracts = inferred_tracts[\n",
        "            inferred_tracts.Sample == s\n",
        "        ].merge(by='Sample')\n",
        "        ind_overlaps = ind_true_tracts.intersect(ind_inferred_tracts)\n",
        "\n",
        "        ntrue_tracts = np.sum([\n",
        "            x[1].End - x[1].Start for x in ind_true_tracts\n",
        "        ])\n",
        "        ninferred_tracts = np.sum([\n",
        "            x[1].End - x[1].Start for x in ind_inferred_tracts\n",
        "        ])\n",
        "        ntrue_positives = np.sum([\n",
        "            x[1].End - x[1].Start for x in ind_overlaps\n",
        "        ])\n",
        "\n",
        "        precision, recall = cal_pr(\n",
        "            ntrue_tracts, ninferred_tracts, ntrue_positives\n",
        "        )\n",
        "        sum_ntrue_tracts += ntrue_tracts\n",
        "        sum_ninferred_tracts += ninferred_tracts\n",
        "        sum_ntrue_positives += ntrue_positives\n",
        "\n",
        "    for s in np.setdiff1d(true_tracts_samples, inferred_tracts_samples):\n",
        "        # ninferred_tracts = 0\n",
        "        ind_true_tracts = true_tracts[true_tracts.Sample == s]\n",
        "\n",
        "        ntrue_tracts = np.sum(\n",
        "            [x[1].End - x[1].Start for x in ind_true_tracts]\n",
        "        )\n",
        "        sum_ntrue_tracts += ntrue_tracts\n",
        "\n",
        "    for s in np.setdiff1d(inferred_tracts_samples, true_tracts_samples):\n",
        "        # ntrue_tracts = 0\n",
        "        ind_inferred_tracts = inferred_tracts[inferred_tracts.Sample == s]\n",
        "\n",
        "        ninferred_tracts = np.sum(\n",
        "            [x[1].End - x[1].Start for x in ind_inferred_tracts]\n",
        "        )\n",
        "        sum_ninferred_tracts += ninferred_tracts\n",
        "\n",
        "    res = res.sort_values(by=['Sample'])\n",
        "\n",
        "    total_precision, total_recall = cal_pr(\n",
        "        sum_ntrue_tracts, sum_ninferred_tracts, sum_ntrue_positives\n",
        "    )\n",
        "    res.loc[len(res.index)] = [\n",
        "        'All', cutoff, total_precision, total_recall, sum_ntrue_tracts,\n",
        "        sum_ninferred_tracts, sum_ntrue_positives\n",
        "    ]\n",
        "\n",
        "    res.fillna('NaN').to_csv(output, sep=\"\\t\", index=False)"
      ],
      "metadata": {
        "id": "jaSFtYRDEvuV"
      },
      "id": "jaSFtYRDEvuV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For example, we can quantify the performance of our model with a cutoff of 0.9:"
      ],
      "metadata": {
        "id": "rfsu1ApxRfDH"
      },
      "id": "rfsu1ApxRfDH"
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(true_tract_file='test/sim.test.true.tracts.bed',\n",
        "         inferred_tract_file='test/sim.test.cutoff0.9.inferred.tracts.bed',\n",
        "         cutoff=0.9, output='test/sim.test.cutoff0.9.performance')"
      ],
      "metadata": {
        "id": "VsIkPxIsjYes"
      },
      "id": "VsIkPxIsjYes",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is our model performance when `cutoff=0.9`:"
      ],
      "metadata": {
        "id": "T1N6Q3kN0e4n"
      },
      "id": "T1N6Q3kN0e4n"
    },
    {
      "cell_type": "code",
      "source": [
        "!cat test/sim.test.cutoff0.9.performance"
      ],
      "metadata": {
        "id": "-wkfeBb9jxCS"
      },
      "id": "-wkfeBb9jxCS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"evaluation-example\"></a>\n",
        "Now we can evaluate our model with a range of different cutoff values:"
      ],
      "metadata": {
        "id": "WP3_Oen6jYqD"
      },
      "id": "WP3_Oen6jYqD"
    },
    {
      "cell_type": "code",
      "source": [
        "cutoffs = [0, .01, .02, .05, .1, .2, .3, .4, .5, .6, .7, .8, .9, .99, .999]\n",
        "for c in cutoffs:\n",
        "    get_inferred_tracts(prediction_file='test/sim.test.predictions', cutoff=c,\n",
        "                        output=f'test/sim.test.cutoff{c}.inferred.tracts.bed')\n",
        "    evaluate(true_tract_file='test/sim.test.true.tracts.bed', cutoff=c,\n",
        "             inferred_tract_file=f'test/sim.test.cutoff{c}.inferred.tracts.bed',\n",
        "             output=f'test/sim.test.cutoff{c}.performance')"
      ],
      "metadata": {
        "id": "DKW5Dv0b1ixG"
      },
      "id": "DKW5Dv0b1ixG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"concat-performance\"></a>\n",
        "Then we can merge the performances from different cutoffs into a table:"
      ],
      "metadata": {
        "id": "xvS8iSWNjxD0"
      },
      "id": "xvS8iSWNjxD0"
    },
    {
      "cell_type": "code",
      "source": [
        "!cat test/*.performance | grep -v Cutoff | awk '{print $2\"\\t\"$3\"\\t\"$4}' | \\\n",
        " sort -nk 1,1 | sed '1iCutoff\\tPrecision\\tRecall' > test/performance.summary\n",
        "!cat test/performance.summary"
      ],
      "metadata": {
        "id": "HHQvSEtUCX-t"
      },
      "id": "HHQvSEtUCX-t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"plot\"></a>\n",
        "Finally, we can visualize the above table as a [precision-recall curve](https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html) with the following `plot()` function."
      ],
      "metadata": {
        "id": "Nr3RoWP0RqTe"
      },
      "id": "Nr3RoWP0RqTe"
    },
    {
      "cell_type": "code",
      "source": [
        "def plot(summary_file: str) -> None:\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Plots the precision-recall curve.\n",
        "\n",
        "    Arguments:\n",
        "        summary_file str: Name of the file storing the performance of a model.\n",
        "\n",
        "    Returns:\n",
        "        None.\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(summary_file, sep=\"\\t\")\n",
        "    plt.plot(df['Recall'], df['Precision'], marker='o', label='PR curve')\n",
        "    plt.plot([0,100],[2,2], label='baseline', linestyle='dashed')\n",
        "    plt.xlim([0,100])\n",
        "    plt.ylim([0,100])\n",
        "    plt.title('Performance')\n",
        "    plt.xlabel('Recall (%)')\n",
        "    plt.ylabel('Precision (%)')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "yKOZPavVMBax"
      },
      "id": "yKOZPavVMBax",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The figure below illustrates a precision-recall curve plot where the x-axis represents recall, and the y-axis denotes precision. Each dot on the curve corresponds to a pair of precision and recall values at different cutoff points. The dashed line represents the baseline, indicative of the performance of a random classifier. In this tutorial, a random classifier arbitrarily labels a fragment as introgressed or non-introgressed with a given probability. Therefore, the precision of the baseline classifier is set to match the true proportion of introgressed fragments in our data. By comparing the precision-recall curve of our model to this baseline, we can directly assess its effectiveness. Essentially, a well-performing model should surpass the random classifier."
      ],
      "metadata": {
        "id": "ySNS0KVXlj-9"
      },
      "id": "ySNS0KVXlj-9"
    },
    {
      "cell_type": "code",
      "source": [
        "plot(summary_file='test/performance.summary')"
      ],
      "metadata": {
        "id": "82KmdI5rPg0D"
      },
      "id": "82KmdI5rPg0D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"task5\"></a>\n",
        "### Task 5: Comprehensive Application"
      ],
      "metadata": {
        "id": "TBJtB-xOCrdP"
      },
      "id": "TBJtB-xOCrdP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please follow the instructions and complete the task:\n",
        "1. Create a folder named `final_task`. Use this folder to store the results of the steps below.\n",
        "2. Download the training dataset from https://huggingface.co/datasets/xin-huang/pgml/resolve/dev/Section_02/sim.training.labeled.features and then move the downloaded file to the `final_task` folder.\n",
        "3. Train a logistic regression model with the downloaded training data. You can use any necessary Python functions and shell commands from above.\n",
        "4. Evaluate your model performance using the test data `sim.test.features` in the `test` folder, by plotting a precision-recall curve across a range of decision cutoffs: `[0, .01, .02, .05, .1, .2, .3, .4, .5, .6, .7, .8, .9, .99, .999]`."
      ],
      "metadata": {
        "id": "Xuvb4E5YwIRf"
      },
      "id": "Xuvb4E5YwIRf"
    },
    {
      "cell_type": "code",
      "source": [
        "# Please implement your code here.\n"
      ],
      "metadata": {
        "id": "TjDySX_A2AdV"
      },
      "id": "TjDySX_A2AdV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "  <summary>\n",
        "    <font size=\"3\" color=\"darkgreen\">\n",
        "      <b>Click for hints</b>\n",
        "    </font>\n",
        "  </summary>\n",
        "\n",
        "  1. **Create the `final_task` folder:** Use the [mkdir](https://linux.die.net/man/1/mkdir) command to create a folder named `final_task`. Remember to prepend `!` to `mkdir` when running it in Jupyter Notebook cells, as shell commands require `!` in this environment.\n",
        "\n",
        "  2. **Download training data:** Follow the provided [example](#wget-example) to download the training data using the [wget](https://linux.die.net/man/1/wget) command. Then, use the [mv](https://linux.die.net/man/1/mv) command to move the downloaded file into the `final_task` folder.\n",
        "\n",
        "  3. **Train logistic regression model:** Utilize the `train()` function (see the [training](#training) section) to train a logistic regression model using the file `sim.training.labeled.features` in the `final_task` folder. Ensure the model file is saved within the `final_task` folder.\n",
        "\n",
        "  4. **Evaluate model and plot precision-recall curve:** Use the `infer()` function (see the [test](#test) section) for making predictions with the `sim.test.features file` located in the `test` folder. Save these predictions in the `final_task` folder. Then, apply the `get_inferred_tracts()` and `evaluate()` functions as shown in this evaluation [example](#evaluation-example) to assess the model performance at different cutoff levels. Use the following command to compile all performance metrics into a single table in the `final_task` folder:\n",
        "  ```\n",
        "  !cat final_task/*.performance | grep -v Cutoff | awk '{print $2\"\\t\"$3\"\\t\"$4}' | \\\n",
        "  sort -nk 1,1 | sed '1iCutoff\\tPrecision\\tRecall' > final_task/performance.summary\n",
        "  ```\n",
        "  Finally, generate a precision-recall curve using the plot function from [above](#plot).\n",
        "\n",
        "  - <details>\n",
        "      <summary>\n",
        "        <font size=\"3\" color=\"darkblue\">\n",
        "          <b>Click for solutions</b>\n",
        "        </font>\n",
        "      </summary>\n",
        "\n",
        "    ```\n",
        "    # Step 1\n",
        "    !mkdir final_task\n",
        "\n",
        "    # Step 2\n",
        "    !wget -c https://huggingface.co/datasets/xin-huang/pgml/resolve/dev/Section_02/sim.training.labeled.features\n",
        "    !mv sim.training.labeled.features final_task\n",
        "\n",
        "    # Step 3\n",
        "    train(feature_file='final_task/sim.training.labeled.features',\n",
        "          model_file='final_task/logistic.regression.model')\n",
        "\n",
        "    # Step 4\n",
        "    infer(feature_file='test/sim.test.features',\n",
        "          model_file='final_task/logistic.regression.model',\n",
        "          output='final_task/sim.test.predictions')\n",
        "\n",
        "    cutoffs = [0, .01, .02, .05, .1, .2, .3, .4, .5, .6, .7, .8, .9, .99, .999]\n",
        "    for c in cutoffs:\n",
        "        get_inferred_tracts(prediction_file='final_task/sim.test.predictions', cutoff=c,\n",
        "                            output=f'final_task/sim.test.cutoff{c}.inferred.tracts.bed')\n",
        "        evaluate(truth_tract_file='test/sim.test.truth.tracts.bed', cutoff=c,\n",
        "                 inferred_tract_file=f'final_task/sim.test.cutoff{c}.inferred.tracts.bed',\n",
        "                 output=f'final_task/sim.test.cutoff{c}.performance')\n",
        "\n",
        "    !cat final_task/*.performance | grep -v Cutoff | awk '{print $2\"\\t\"$3\"\\t\"$4}' | \\\n",
        "    sort -nk 1,1 | sed '1iCutoff\\tPrecision\\tRecall' > final_task/performance.summary\n",
        "\n",
        "    plot(summary_file='final_task/performance.summary')\n",
        "    ```\n",
        "  </details>\n",
        "</details>"
      ],
      "metadata": {
        "id": "ceE3Nr7_mbhN"
      },
      "id": "ceE3Nr7_mbhN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"summary\"></a>\n",
        "## Summary\n",
        "\n",
        "In this section, we covered:\n",
        "1. The fundamental workflow of **supervised learning**.\n",
        "2. The process of training a **logistic regression** model to predict ghost introgressed fragments in genomes, approaching it as a **binary classification** problem.\n",
        "3. The evaluation of our model performance using two key metrics: **precision** and **recall**."
      ],
      "metadata": {
        "id": "PeCXXAfaikkC"
      },
      "id": "PeCXXAfaikkC"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "rBLqf2pwWjIq"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}